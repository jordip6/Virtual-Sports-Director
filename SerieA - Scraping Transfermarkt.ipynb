{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests import get\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from os.path  import basename\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from time import sleep\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': \n",
    "           'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process League Table\n",
    "page = 'https://www.transfermarkt.com/serie-a/startseite/wettbewerb/IT1/plus/?saison_id=2017'\n",
    "\n",
    "tree = requests.get(page, headers = headers)\n",
    "soup = BeautifulSoup(tree.content, 'html.parser')\n",
    "\n",
    "#Create an empty list to assign these values to\n",
    "teamLinks = []\n",
    "\n",
    "#Extract all links with the correct CSS selector\n",
    "links = soup.select(\"a.vereinprofil_tooltip\")\n",
    "\n",
    "#We need the location that the link is pointing to, so for each link, take the link location. \n",
    "#Additionally, we only need the links in locations 1,3,5,etc. of our list, so loop through those only\n",
    "for i in range(1,61,3):\n",
    "    teamLinks.append(links[i].get(\"href\"))\n",
    "    \n",
    "#For each location that we have taken, add the website before it - this allows us to call it later\n",
    "for i in range(len(teamLinks)):\n",
    "    teamLinks[i] = \"https://www.transfermarkt.com\"+teamLinks[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an empty list for our player links to go into\n",
    "playerLinks = []\n",
    "\n",
    "#Run the scraper through each of our 20 team links\n",
    "for i in range(len(teamLinks)):\n",
    "\n",
    "    #Download and process the team page\n",
    "    page = teamLinks[i]\n",
    "    tree = requests.get(page, headers = headers)\n",
    "    soup = BeautifulSoup(tree.content, 'html.parser')\n",
    "\n",
    "    #Extract all links\n",
    "    links = soup.select(\"a.spielprofil_tooltip\")\n",
    "    \n",
    "    #For each link, extract the location that it is pointing to\n",
    "    for j in range(len(links)):\n",
    "        playerLinks.append(links[j].get(\"href\"))\n",
    "\n",
    "#Add the location to the end of the transfermarkt domain to make it ready to scrape\n",
    "for j in range(len(playerLinks)):\n",
    "    playerLinks[j] = \"https://www.transfermarkt.com\"+playerLinks[j]\n",
    "\n",
    "#The page list the players more than once - let's use list(set(XXX)) to remove the duplicates\n",
    "playerLinks = list(set(playerLinks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    }
   ],
   "source": [
    "#Create the df\n",
    "df = pd.DataFrame(columns= ['Link','Name','Edad','Position','Club', 'Team','Representante','Fin Contrato','Value'])\n",
    "#Run the scraper through each of the players\n",
    "for i in range(len(playerLinks)):    \n",
    "#Download and process the players page\n",
    "    page = playerLinks[i]\n",
    "    tree = requests.get(page, headers=headers)\n",
    "    soup = BeautifulSoup(tree.content, 'html.parser')\n",
    "    \n",
    "#Extract info  \n",
    "    table = soup.find(\"table\", { \"class\" : \"auflistung\" })\n",
    "    table = table.find_all('td')  \n",
    "    try:\n",
    "        name= table[0].text.rstrip('<td>')\n",
    "    except: \n",
    "        name=\"NA\"       \n",
    "    try:\n",
    "        edad= table[2].text.rstrip('<td>')\n",
    "    except:\n",
    "        edad = \"NA\"       \n",
    "    try:\n",
    "        position = table[5].text.rstrip('<td>').replace('\\n','').replace(' ','')\n",
    "    except:\n",
    "        position = \"NA\"       \n",
    "    try:\n",
    "        representacion= table[7].text.rstrip('<td>').replace('\\n','')\n",
    "    except:\n",
    "        representacion=\"NA\"   \n",
    "    try:\n",
    "        club=table[8].text.rstrip('<td>')\n",
    "    except:\n",
    "        club =\"NA\"   \n",
    "    try:\n",
    "        contract= table[10].text.rstrip('<td>')\n",
    "    except:\n",
    "        contract = \"NA\"   \n",
    "    \n",
    "    try:\n",
    "        team= table[10].text.rstrip('<td>')\n",
    "    except:\n",
    "        team = \"NA\" \n",
    "        \n",
    "    try:\n",
    "        values = soup.find(\"div\", {\"class\": \"dataMarktwert\"})\n",
    "        values=values.text.replace('\\n','').split(',')[0]\n",
    "        values=values.split(' ')[0]\n",
    "    except:\n",
    "        values = \"NA\"\n",
    "    \n",
    "    dfi = pd.DataFrame({'Link':[playerLinks[i]],'Name':[name],'Edad':[edad],'Position':[position],'Club':[club],'Team' : [team],'Representante':[representacion],'Fin Contrato':[contract],'Value':[values]})\n",
    "    df = df.append(dfi)   \n",
    "\n",
    "df_excel = df.to_excel(r'\\Users\\jordi\\OneDrive\\Escritorio\\TFM\\Dataset\\SerieA.xlsx')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
